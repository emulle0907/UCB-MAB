{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEpsilons(eigenVals, eigenVects, M): # only works for 2 agents\n",
    "    eps_n = np.sqrt(M) * np.sum((np.abs(eigenVals[1:]) / (1 - np.abs(eigenVals[1:]))))\n",
    "    vpos = 0\n",
    "    vneg = 0\n",
    "    b = 0\n",
    "    eps_c = 0\n",
    "    for i in range(M):\n",
    "        if((eigenVects * np.transpose(eigenVects))[i,i] >= 0):\n",
    "            vpos = np.sum(eigenVects[i,0] * eigenVects[i,1])\n",
    "        if((eigenVects * np.transpose(eigenVects))[i,i] <= 0):\n",
    "            vneg = np.sum(eigenVects[i,0] * eigenVects[i,1])\n",
    "    \n",
    "        if(eigenVals[0] * eigenVals[1] >= 0 and (eigenVects * np.transpose(eigenVects))[i,i] >= 0):\n",
    "            b = vpos * (eigenVects * (np.transpose(eigenVects)))[i,i]\n",
    "        elif(eigenVals[0] * eigenVals[1] >= 0 and (eigenVects * np.transpose(eigenVects))[i,i] <= 0):\n",
    "            b = vneg * (eigenVects * (np.transpose(eigenVects)))[i,i]\n",
    "        else:\n",
    "            b = max(np.abs(vneg), vpos) * np.abs((eigenVects * np.transpose(eigenVects))[i,i])\n",
    "    \n",
    "    for p in range(M - 1):\n",
    "        lambdas = np.abs(eigenVals[p] * eigenVals[p+1])\n",
    "        eps_c += (lambdas / (1 - lambdas)) * b\n",
    "    eps_c *= M\n",
    "    return eps_n, eps_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, num_arms):\n",
    "        # Number of total steps\n",
    "        self.total_arm_selections = np.ones(num_arms)\n",
    "        # Total reward for each arm\n",
    "        self.arm_rewards = np.zeros(num_arms)\n",
    "        # Total mean reward from all arms\n",
    "        self.mean_rewards = self.arm_rewards / self.total_arm_selections\n",
    "    \n",
    "    def updateSelections(self, index):\n",
    "        self.total_arm_selections[index] += 1\n",
    "    \n",
    "    def updateRewards(self, index, reward):\n",
    "        self.arm_rewards[index] = reward\n",
    "    \n",
    "    def updateMeans(self):\n",
    "        self.mean_rewards = self.arm_rewards / self.total_arm_selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arm:\n",
    "    def __init__(self):\n",
    "        self.reward_distrib = np.random.normal(0, 1)\n",
    "    \n",
    "    def getReward(self):\n",
    "        return np.random.normal(self.reward_distrib, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5 # number of arms\n",
    "M = 2 # number of agents\n",
    "arms = []\n",
    "agents = []\n",
    "arm_selections = []\n",
    "arm_rewards = []\n",
    "mean_rewards = []\n",
    "\n",
    "indicators = np.zeros([M,N])\n",
    "rewards = np.zeros([M,N])\n",
    "\n",
    "T = 1000 # time to run for\n",
    "gamma = 1.2 # must be greater than 1 according to paper\n",
    "\n",
    "for i in range(N): # initialize arms\n",
    "    arms.append(Arm())\n",
    "\n",
    "for i in range(M): # initialize agents\n",
    "    agents.append(Agent(N))\n",
    "\n",
    "for i in range(len(agents)): # get arrays of selections and rewards\n",
    "    arm_selections.append(agents[i].total_arm_selections)\n",
    "    arm_rewards.append(agents[i].arm_rewards)\n",
    "arm_selections = np.array(arm_selections)\n",
    "arm_rewards = np.array(arm_rewards)\n",
    "\n",
    "for i in range(len(arms)): # initialize with 1 round of rewards\n",
    "    for j in range(len(agents)):\n",
    "        reward = arms[i].getReward()\n",
    "        arm_rewards[j][i] = reward\n",
    "mean_rewards = arm_rewards/arm_selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from([0, 1])\n",
    "G.add_edges_from([(0, 1)])\n",
    "A = nx.adjacency_matrix(G)\n",
    "L = nx.laplacian_matrix(G)\n",
    "\n",
    "M = len(G)\n",
    "\n",
    "maxDeg = 0\n",
    "for i in range(len(G)): # find max degree in graph\n",
    "    if G.degree[i] > maxDeg:\n",
    "        maxDeg = G.degree[i]\n",
    "\n",
    "kappa = .2\n",
    "P = np.eye(len(G)) - (kappa*L / maxDeg) # calculate P matrix from paper\n",
    "eigenVals, eigenVects = np.linalg.eig(P) # calculate P's eigenvectors and eigenvalues\n",
    "\n",
    "_, eps_c = calculateEpsilons(eigenVals, eigenVects, M) # calculate epsilons eps_n and eps_c from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = 0\n",
    "sampledIndex = 0\n",
    "maxRwd = 0\n",
    "maxIndex = 0\n",
    "for t in range(1,T+1):\n",
    "    for k in range(len(agents)):\n",
    "        mean_rewards = arm_rewards/arm_selections # update u_i(t)\n",
    "        arm_selections = P*arm_selections + P*indicators # update s_i(t)\n",
    "        arm_rewards = P*arm_rewards + P*rewards # update n_i(t)\n",
    "        \n",
    "        maxRwd = 0\n",
    "        for i in range(len(arms)): # loop through arms to find max reward to decide which arm to choose\n",
    "            val = mean_rewards[k,i] + 1 * np.sqrt((2 * gamma) * \n",
    "                        ((arm_selections[k,i] + eps_c) / M*arm_selections[k,i])\n",
    "                        * (np.log(t) / arm_selections[k,i]))\n",
    "            if val > maxRwd:\n",
    "                maxRwd = val\n",
    "                maxIndex = i\n",
    "        indicators = np.zeros([M,N])\n",
    "        rewards = np.zeros([M,N])\n",
    "        sampledIndex = maxIndex # set index of chosen arm\n",
    "        reward = arms[sampledIndex].getReward() # get reward from chosen arm\n",
    "        indicators[k,sampledIndex] = 1 # set indicator to 1 for chosen arm\n",
    "        rewards[k,sampledIndex] = reward # set r_i(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.50048675,  2.18771725, -1.54392025,  0.38185153, -0.29738432],\n",
       "        [ 0.50048675,  2.1881889 , -1.54392025,  0.38185153, -0.29738432]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.5000000e+00, 1.0001875e+03, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00],\n",
       "        [1.5000000e+00, 9.9981250e+02, 1.0000000e+00, 1.0000000e+00,\n",
       "         1.0000000e+00]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 7.50730128e-01,  2.18725993e+03, -1.54392025e+00,\n",
       "          3.81851531e-01, -2.97384324e-01],\n",
       "        [ 7.50730128e-01,  2.18744380e+03, -1.54392025e+00,\n",
       "          3.81851531e-01, -2.97384324e-01]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
